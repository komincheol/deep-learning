{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ch.2 Classifying with k-Nearest Neighbors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## 2.1 Classifying with distance measurements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### k-Nearest Neighbors (kNN)\n",
    "* 장점: 높은 정확성, 이상치(outlier)에 둔감, 데이터에 대한 가정 불필요\n",
    "* 단점: 계산 비용 높음, 많은 메모리 필요\n",
    "* 자료: 수치형, 명목형"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $ 교재 p.24~25 설명"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### General approach to kNN\n",
    "1. Collect:\n",
    "  - 모든 방법\n",
    "2. Prepare:\n",
    "  - 수치형 값(거리 계산을 위해), 구조적 데이터가 가장 좋음\n",
    "3. Analyze:\n",
    "  - 모든 방법\n",
    "4. Train:\n",
    "  - 필요 없음\n",
    "5. Test:\n",
    "  - 오류율(error rate) 계산\n",
    "6. Use:\n",
    "  - 구조화된 수치 입력 및 출력 데이터 준비\n",
    "  - 그런 다음 입력에 대해 kNN 알고리즘 적용하여 입력 데이터가 어디에 속하는지 판단\n",
    "  - 그후 애플리케이션에서 판단된 클래스에 대해 어떤 액션을 취함"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1.1 Prepare: Importing data with Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def createDataSet():\n",
    "    group = np.array([[1.0, 1.1], [1.0, 1.0], [0, 0], [0, 0.1]])\n",
    "    labels = ['A', 'A', 'B', 'B']\n",
    "    return group, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "group, labels = createDataSet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "type(group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import kNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "group, labels = kNN.createDataSet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "group.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1.2 Putting the kNN classification algorithm into action"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $ kNN 알고리즘 의사코드 (교재 p.29)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "##### Listing 2.1 k-Nearest Neighbors algorithm for Python 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Python2 버전\n",
    "def classify0_p2(inX, dataSet, labels, k):\n",
    "    dataSetSize = dataSet.shape[0]   #1\n",
    "    diffMat = tile(inX, (dataSetSize, 1)) - dataSet   #2\n",
    "    sqDiffMat = diffMat**2\n",
    "    sqDistances = sqDiffMat.sum(axis=1)\n",
    "    distances = sqDistances**0.5\n",
    "    sortedDistIndices = distances.argsort()\n",
    "    classCount = {}\n",
    "    for i in range(k):\n",
    "        voteIlabel = labels[sortedDistIndices[i]]\n",
    "        classCount[voteIlabel] = classCount.get(voteIlabel, 0) + 1\n",
    "    sortedClassCount = sorted(classCount.iteritems(), key=operator.itemgetter(1), reverse=True)   #3\n",
    "    return sortedClassCount[0][0]   # 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# classify0 함수의 매개변수 설정\n",
    "# dataSet: numpy.ndarray 타입\n",
    "inX = [0, 0]\n",
    "dataSet = group\n",
    "k = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 데이터 수 (2차원 배열의 행 개수) -- Python3 에선 불필요\n",
    "dataSetSize = dataSet.shape[0]; dataSetSize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 두 점 간 거리 구하기\n",
    "* 피타고라스의 정리: https://ko.wikipedia.org/wiki/피타고라스의_정리 \n",
    "* 두 점 사이의 거리(선분의 길이): https://www.youtube.com/watch?v=iSInGiiUOhI\n",
    "* 두 점을 지나는 직선의 기울기: https://www.youtube.com/watch?v=2hKtZXyV-9o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 분류하고자 하는 점 inX를 데이터 집합의 행 개수만큼 복제한 후 데이터 집합의 점과의 차를 구함\n",
    "diffMat = inX - dataSet; diffMat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $ numpy.tile - for Python2\n",
    "https://docs.scipy.org/doc/numpy/reference/generated/numpy.tile.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "a = np.array([0, 1, 2]); a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.tile(a, 2)    # 1차원 배열"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.tile(a, (1, 2))   # 2차원 배열"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.tile(a, (2, 1))   # 2차원 배열"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.tile(a, (2, 1, 2))   # 3차원 배열"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.tile(a, (2, 3, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "b = np.array([[0, 1], [2, 3]]); b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.tile(b, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.tile(b, (1, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.tile(b, (2, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.tile(b, (3, 2, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(dataSetSize)\n",
    "np.tile([0, 0], (dataSetSize, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### -- end of numpy.tile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 차를 제곱하고\n",
    "sqDiffMat = diffMat**2; sqDiffMat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 행 방향으로 더한 후\n",
    "sqDistances = sqDiffMat.sum(axis=1); sqDistances   # row-wise summation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $ numpy.ndarry.sum = numpy.sum\n",
    "* https://docs.scipy.org/doc/numpy/reference/generated/numpy.ndarray.sum.html\n",
    "* https://docs.scipy.org/doc/numpy/reference/generated/numpy.sum.html#numpy.sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.sum([])   # 빈 배열의 합"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.sum([1.1, 0.7, 0.2, 1.5], dtype=np.int32)   # 실수를 32비트 정수형으로 변환한 후 합계"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.sum([0.5, 1.5])   # axis 옵션이 없으면 모든 원소를 더함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(np.sum([[0, 1], [0, 5]]))\n",
    "print(np.sum([[0, 1], [0, 5]], axis=0))\n",
    "print(np.sum([[0, 1], [0, 5]], axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(np.ones(5))\n",
    "print(np.ones((3, 4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(np.ones(5).sum())   # ndarray 객체의 메소드로 사용\n",
    "print(np.ones((3, 4)).sum(axis=0))\n",
    "print(np.ones((3, 4)).sum(axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = np.array([[2, 3], [8, 4]]); a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(a.sum())\n",
    "print(a.sum(0))\n",
    "print(a.sum(axis=0))\n",
    "print(a.sum(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### -- end of numpy.ndarray.sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 제곱근을 적용하여 inX와 모든 데이터 셋 점간의 거리를 구함\n",
    "distances = sqDistances**0.5; distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 거리가 가까운 순으로 정렬\n",
    "# 거리를 정렬하되 정렬된 결과의 점이 필요하므로 인덱스 값이 정렬되도록 함\n",
    "sortedDistIndices = distances.argsort(); sortedDistIndices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $ numpy.argsort\n",
    "* 반환값: 배열이 정렬되었을 때의 인덱스 배열(ndarray, int)\n",
    "* 마지막 축을 기준으로 정렬(기본값)\n",
    "https://docs.scipy.org/doc/numpy/reference/generated/numpy.argsort.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 1차원 배열\n",
    "x = np.array([3, 1, 2]); print(x)\n",
    "print(np.argsort(x))\n",
    "print(x[np.argsort(x)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 2차원 배열\n",
    "x = np.array([[0, 3], [2, 2]]); print(x)\n",
    "print(np.argsort(x, axis=0))\n",
    "print(np.argsort(x, axis=1))\n",
    "print(np.argsort(x, axis=-1))   # 마지막 축을 기준으로 정렬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 3차원 배열\n",
    "x = np.array([[[8, 1, 4], [1, 2, 5]], [[4, 2, 7], [6, 5, 4]]]); print(x)\n",
    "print(np.argsort(x, axis=2))\n",
    "print(np.argsort(x))\n",
    "print(np.argsort(x, axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 키 값으로 정렬\n",
    "x = np.array([(1, 0), (0, 1)], dtype=[('x', '<i4'), ('y', '<i4')]); x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### numpy의 구조적 데이터 타입을 사용한 인자 정렬\n",
    "* numpy.dtype: https://docs.scipy.org/doc/numpy/reference/generated/numpy.dtype.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.argsort(x, order=('x', 'y'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.argsort(x, order=('y', 'x'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### -- end of numpy.argsort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 딕셔너리 변수 준비\n",
    "classCount = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for i in range(k):   # k 회수만큼 반복\n",
    "    voteIlabel = labels[sortedDistIndices[i]]\n",
    "    classCount[voteIlabel] = classCount.get(voteIlabel, 0) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# k번째 가까운 점의 인덱스 값을 구한 후 그 점의 레이블을 저장\n",
    "# 처음 수행한다면\n",
    "print(sortedDistIndices[0])\n",
    "print(labels)\n",
    "voteIlabel = labels[sortedDistIndices[0]]; print(voteIlabel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 레이블을 키, 레이블의 회수를 값으로 하는 딕셔너리 classCount\n",
    "# classCount 딕셔너리의 키 값에 없는 레이블(처음 나타난 레이블)이면 get 함수가 0을 리턴\n",
    "print(classCount)\n",
    "print(classCount.get(voteIlabel, 0))\n",
    "print(classCount.get(voteIlabel, 0) + 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $ 딕셔너리 함수: get\n",
    "https://wikidocs.net/16 에서 'get' 검색"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# classCount 딕셔너리 갱신하고 이후 k 회수만큼 반복\n",
    "classCount[voteIlabel] = classCount.get(voteIlabel, 0) + 1; print(classCount)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classCount = {}\n",
    "for i in range(k):   # k 회수만큼 반복\n",
    "    voteIlabel = labels[sortedDistIndices[i]]\n",
    "    classCount[voteIlabel] = classCount.get(voteIlabel, 0) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classCount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(classCount)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sortedClassCount = sorted(classCount.iteritems(), key=operator.itemgetter(1), reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "##### Listing 2.1 k-Nearest Neighbors algorithm for Python 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Python3 버전\n",
    "def classify0(inX, dataSet, labels, k):\n",
    "    diffMat = inX - dataSet\n",
    "    sqDiffMat = diffMat**2\n",
    "    sqDistances = sqDiffMat.sum(axis=1)\n",
    "    distances = sqDistances**0.5\n",
    "    sortedDistIndices = distances.argsort()\n",
    "    classCount = {}\n",
    "    for i in range(k):\n",
    "        voteIlabel = labels[sortedDistIndices[i]]\n",
    "        classCount[voteIlabel] = classCount.get(voteIlabel, 0) + 1\n",
    "    sortedClassCount = sorted(classCount, key=classCount.get, reverse=True)\n",
    "    return sortedClassCount[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $ Python3 정렬\n",
    "https://docs.python.org/3/howto/sorting.html\n",
    "* sorted() 함수: https://docs.python.org/3/library/functions.html#sorted\n",
    "    - key 인자: 정렬에 사용될 함수를 받음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sortedClassCount = sorted(classCount, key=classCount.get, reverse=True); sortedClassCount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "type(sortedClassCount)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(sortedClassCount[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### kNN 테스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import kNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "group, labels = kNN.createDataSet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "kNN.classify0([0, 0], group, labels, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "kNN.classify0([1, 0.8], group, labels, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 2.2 Example: improving matches from a dating site with kNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 내 친구 헬렌\n",
    "* 3 types of people she went out with:\n",
    "    - People she didn't like\n",
    "    - People she liked in small doses\n",
    "    - People she liked in large doese"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example: using kNN on results from a dating site\n",
    "1. Collect:\n",
    "  - 텍스트 파일 제공됨\n",
    "2. Prepare:\n",
    "  - 파이썬에서 텍스트 파일 파싱\n",
    "3. Analyze:\n",
    "  - Matplotlib을 사용하여 데이터의 2차원 플롯 생성\n",
    "4. Train:\n",
    "  - kNN 알고리즘에는 훈련이 필요없음\n",
    "5. Test:\n",
    "  - 헬렌이 준 데이터 중 일부를 테스트 데이터로 사용하는 함수 작성\n",
    "  - 테스트 데이터는 비테스트 데이터와 구별\n",
    "  - 예측된 클래스가 실제 클래스와 일치하지 않으면 오류\n",
    "6. Use:\n",
    "  - 헬렌이 입력한 몇몇 값을 바탕으로 헬렌이 좋아하는 상대인지 예측하는 간단한 명령행 프로그램 작성"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2.1 Prepare: parsing data from a text file\n",
    "* datingTestSet.txt\n",
    " - 1,000 entries\n",
    " - features\n",
    "   - Number of frequent flyer miles earned per year\n",
    "   - Percentage of time spent playing video games\n",
    "   - Liters of ice cream consumed per week "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### file2matrix 함수\n",
    "* 텍스트 파일의 데이터를 분류기가 사용할 수 있는 형태로 변환\n",
    "* 입력: 파일 이름\n",
    "* 출력: 훈련 데이터(행렬), 클래스 레이블(벡터)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "##### Listing 2.2 Text record to NumPy parsing code for Python 2, 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# 원본: Python3에서도 실행 가능\n",
    "def file2matrix_p2(filename):\n",
    "    fr = open(filename)\n",
    "    \n",
    "    # 훈련 데이터(returnMat)와 클래스 레이블(classLabelVector) 변수 준비\n",
    "    numberOfLines = len(fr.readlines())      # 텍스트 파일의 라인 개수\n",
    "    returnMat = np.zeros((numberOfLines, 3)) # 텍스트_라인수 X 3 크기의 영행렬 준비\n",
    "    classLabelVector = []                    # 클래스 레이블 변수 준비\n",
    "    \n",
    "    # readlines() 는 파일 끝까지 읽은 뒤 포인터를 파일의 처음으로 돌려놓지 않으므로\n",
    "    # 파일 내용을 다시 읽으려면 open() 을 사용하여 파일을 다시 읽어야 한다.\n",
    "    fr = open(filename)\n",
    "    index = 0            # 반환할 행렬의 로우 인덱스\n",
    "    \n",
    "    for line in fr.readlines():\n",
    "        # 문자열 양 옆 공백 제거\n",
    "        line = line.strip()\n",
    "        \n",
    "        # 문자열을 탭('\\t')을 기준으로 단어로 분리하여 리스트로 반환\n",
    "        listFromLine = line.split('\\t')\n",
    "        \n",
    "        # returnMat의 인덱스 로우에 위 리스트의 첫 번째부터 세 번째 값을 저장\n",
    "        returnMat[index, :] = listFromLine[0:3]\n",
    "        \n",
    "        # classLabelVector 리스트에 listFromLine 리스트의 마지막 값을 저장\n",
    "        classLabelVector.append(listFromLine[-1])\n",
    "        index += 1\n",
    "        \n",
    "    return returnMat, classLabelVector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 원본 file2matrix 함수 설명"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filename = 'datingTestSet.txt'\n",
    "fr = open(filename)    # default file access mode: read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 훈련 데이터(returnMat)와 클래스 레이블(classLabelVector) 변수 준비\n",
    "numberOfLines = len(fr.readlines())      # 텍스트 파일의 라인 개수\n",
    "returnMat = np.zeros((numberOfLines, 3)) # 텍스트_라인수 X 3 크기의 영행렬 준비\n",
    "classLabelVector = []                    # 클래스 레이블 변수 준비\n",
    "print(numberOfLines)\n",
    "print(returnMat)\n",
    "print(classLabelVector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# readlines() 는 파일 끝까지 읽은 뒤 포인터를 파일의 처음으로 돌려놓지 않으므로\n",
    "# 파일 내용을 다시 읽으려면 open() 을 사용하여 파일을 다시 읽어야 한다.\n",
    "lines = fr.readlines(); lines  # lines는 빈 리스트\n",
    "fr = open(filename)            # 파일을 다시 읽어야 한다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "index = 0    # 반환할 행렬의 로우 인덱스"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lines = fr.readlines()\n",
    "print(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "line = lines[index]\n",
    "print(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 문자열 양 옆 공백 제거\n",
    "line = line.strip()\n",
    "print(line)\n",
    "type(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 문자열을 탭('\\t')을 기준으로 단어로 분리하여 리스트로 반환\n",
    "listFromLine = line.split('\\t')\n",
    "print(line)\n",
    "type(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# returnMat의 인덱스 로우에 위 리스트의 첫 번째부터 세 번째 값을 저장\n",
    "returnMat[index, :] = listFromLine[0:3]\n",
    "print(returnMat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# classLabelVector 리스트에 listFromLine 리스트의 마지막 값을 저장\n",
    "classLabelVector.append(listFromLine[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 인덱스 1 증가하고 반복(for 문)\n",
    "index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Listing 2.2 Enhanced text record to NumPy parsing code for Python 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# 수정본\n",
    "#   - 파일을 한 번만 연다\n",
    "#   - 즉, open(), readlines()를 한 번만 호출\n",
    "def file2matrix(filename):\n",
    "    fr = open(filename)\n",
    "    index = 0                     # 반환할 행렬의 로우 인덱스\n",
    "    classLabelVec = []            # 클래스 레이블 변수 준비\n",
    "    for line in fr.readlines():\n",
    "        # 문자열 양 옆 공백 제거 후 탭('\\t')을 기준으로 단어로 분리한 리스트\n",
    "        lineList = line.strip().split('\\t')\n",
    "        \n",
    "        # lineList의 마지막 컬럼값(레이블)을 클래스 레이블 변수에 추가\n",
    "        classLabelVec.append(lineList[-1])\n",
    "        \n",
    "        # List Comprehension in Python\n",
    "        feature = [float(value) for value in lineList[0:3]]\n",
    "        \n",
    "        # 처음 읽은 라인이면 returnMat 변수 초기화, 아니면 returnMat 변수에 행 추가\n",
    "        # 아래 if else 문을 한 문장으로 표현\n",
    "        returnMat = np.vstack((returnMat, feature)) \\\n",
    "                        if index != 0 else np.array(feature)\n",
    "        #if (index == 0):\n",
    "        #    returnMat = np.array(feature)\n",
    "        #else:\n",
    "        #    returnMat = np.vstack((returnMat, feature))\n",
    "        index += 1\n",
    "    return returnMat, classLabelVec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 수정된 file2matrix 함수 설명"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filename = 'datingTestSet.txt'\n",
    "fr = open(filename)\n",
    "lines = fr.readlines()\n",
    "index = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### $ Python List Comprehension\n",
    "[x for x in iterable]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# List Comprehension in Python\n",
    "[value for value in lines[index].strip().split('\\t')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lineList = lines[index].strip().split('\\t')\n",
    "feature = [float(value) for value in lineList[0:3]]\n",
    "print(lineList)\n",
    "print(feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 처음 읽은 라인이면 returnMat 변수 초기화, 아니면 returnMat 변수에 행 추가\n",
    "returnMat = np.vstack((returnMat, feature)) if index != 0 else np.array(feature)\n",
    "print(returnMat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 위 문장은 아래의 if ~ else ~ 를 간략히 표현한 것\n",
    "if (index == 0):\n",
    "    returnMat = np.array(feature)\n",
    "else:\n",
    "    returnMat = np.vstack((returnMat, feature))\n",
    "print(returnMat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $ numpy.vstack\n",
    "* numpy 배열들을 입력받아 수직으로 쌓은 후 numpy 배열 반환\n",
    "* 첫 번째 축(차원)을 제외한 모든 축의 크기가 같아야 함\n",
    "* https://docs.scipy.org/doc/numpy/reference/generated/numpy.vstack.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = np.array([1, 2, 3])\n",
    "b = np.array([2, 3, 4])\n",
    "c = np.array([3, 4, 5])\n",
    "np.vstack((a, b, c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "np.vstack((a, b, c, [9, 8, 7]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = np.array([[1, 2,], [3, 4]])\n",
    "b = np.array([[11, 22], [33, 44]])\n",
    "c = np.array([[4, 5], [5, 4],\n",
    "              [9, 8], [8, 9]])\n",
    "d = np.array([[1, 2, 3], [4, 5, 6]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.vstack((a, b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.vstack((a, c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.vstack((a, b, c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.vstack((a, d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = np.zeros((3, 4, 5)); a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "b = np.ones((2, 4, 4)); b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.vstack((a, b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "b = np.ones((2, 4, 5)); b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.vstack((a, b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### -- end of numpy.vstack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import kNN\n",
    "import importlib\n",
    "importlib.reload(kNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "datingDataMat, datingLabels = kNN.file2matrix('datingTestSet.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(datingDataMat)\n",
    "print(len(datingDataMat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "datingLabels[0:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 원본 테스트\n",
    "#datingDataMat2, datingLabels2 = file2matrix_p2('datingTestSet.txt')\n",
    "#print(datingDataMat2)\n",
    "#print(len(datingDataMat2))\n",
    "#datingLabels2[0:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### !NumPy의 array와 Python의 array를 혼용하지 말자.!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2.2 Analyze: creating scatter plots with Matplotlib\n",
    "  - 산포도를 통해 헬렌이 좋아할 사람을 분류할 수 있는 특징들(features)을 찾아보자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import kNN\n",
    "import importlib; importlib.reload(kNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "datingDataMat, datingLabels = kNN.file2matrix('datingTestSet2.txt')\n",
    "np.array([int(x) for x in datingLabels[:10]]) * 15.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "ax.scatter(datingDataMat[:, 1], datingDataMat[:, 2],\n",
    "           15.0*np.array([int(x) for x in datingLabels]),\n",
    "           15.0*np.array([int(x) for x in datingLabels]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "datingDataMat, datingLabels = kNN.file2matrix('datingTestSet.txt')\n",
    "title0 = 'The Number of Frequent Flyer Miles Earned Per Year'\n",
    "title1 = 'Percentage of Time Spent Playing Video Games'\n",
    "title2 = 'Liters of Ice Cream Consumed Per Week'\n",
    "data0, data1, data2 = datingDataMat[:, 0], datingDataMat[:, 1], datingDataMat[:, 2]\n",
    "legendString = ['Did Not Like', 'Liked in Small Doses', 'Liked in Large Doses']\n",
    "output = [('b', 20) if x == 'didntLike' else ('g', 30) \n",
    "                    if x == 'smallDoses' else ('r', 50) \n",
    "                    for x in datingLabels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "colors = [x for (x, y) in output]\n",
    "markers = [y for (x, y) in output]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#colors = ['blue' if x == 'didntLike' else 'green' if x == 'smallDoses' else 'red' for x in datingLabels]\n",
    "#markers = [10 if x == 'didntLike' else 30 if x == 'smallDoses' else 50 for x in datingLabels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fig = plt.figure()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ax = fig.add_subplot(111)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# x axis: Percentage of Time Spent Playing Video Games\n",
    "# y axis: Liters of Ice Cream Consumed Per Week\n",
    "ax.scatter(data1, data2, c=colors, s=markers, edgecolors='k')\n",
    "plt.xlabel(title1)\n",
    "plt.ylabel(title2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "type1 = ax.scatter([10], [-10], s=20, c='b')\n",
    "type2 = ax.scatter([10], [-15], s=30, c='g')\n",
    "type3 = ax.scatter([10], [-20], s=50, c='r')\n",
    "ax.legend([type1, type2, type3], legendString, loc=1)\n",
    "minX, maxX = min(data1), max(data1)\n",
    "minY, maxY = min(data2), max(data2)\n",
    "marginX, marginY = np.multiply(0.05, [maxX - minX, maxY - minY])\n",
    "ax.axis([minX - marginX, maxX + marginX, minY - marginY, maxY + marginY])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# x axis: The Number of Frequent Flyer Miles Earned Per Year\n",
    "# y axis: Liters of Ice Cream Consumed Per Week\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "ax.scatter(data0, data2, c=colors, s=markers, edgecolors='k')\n",
    "plt.xlabel(title0)\n",
    "plt.ylabel(title2)\n",
    "ax.legend([type1, type2, type3], legendString, loc=1)\n",
    "minX, maxX = min(data0), max(data0)\n",
    "minY, maxY = min(data2), max(data2)\n",
    "marginX, marginY = np.multiply(0.05, [maxX - minX, maxY - minY])\n",
    "ax.axis([minX - marginX, maxX + marginX, minY - marginY, maxY + marginY])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# x axis: The Number of Frequent Flyer Miles Earned Per Year\n",
    "# y axis: Percentage of Time Spent Playing Video Games\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "ax.scatter(data0, data1, c=colors, s=markers, edgecolors='k')\n",
    "plt.xlabel(title0)\n",
    "plt.ylabel(title1)\n",
    "ax.legend([type1, type2, type3], legendString, loc='best')\n",
    "minX, maxX = min(data0), max(data0)\n",
    "minY, maxY = min(data1), max(data1)\n",
    "marginX, marginY = np.multiply(0.05, [maxX - minX, maxY - minY])\n",
    "ax.axis([minX - marginX, maxX + marginX, minY - marginY, maxY + marginY])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### List Comprehension with if else if else"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "l = [22, 13, 45, 50, 98, 69, 43, 44, 1]\n",
    "[x+1 if x >= 45 else x+5 for x in l]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "l = [1, 2, 3, 4, 5]\n",
    "['yes' if v == 1 else 'no' if v == 2 else 'idle' for v in l]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 특징들 간의 관계를 그림으로 분석한 결과:\n",
    " * '비디오 게임 시간'과 '연간 비행 마일 수'가 분류에 의미 있는 특징으로 결정됨\n",
    " * 즉, 헬렌이 좋아할만한 남자 친구를 찾는(분류하는) 특징으로 '비디오 게임 시간'과 '연간 비행 마일 수'를 선택"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 2.2.3 Prepare: normalizing numeric values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $ 교재 p.37 설명"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 헬렌의 예에서 '연간 항공 마일리지 수' 특징이 거리를 계산하는데 있어 큰 영향을 미친다.\n",
    "#### 원인:\n",
    " * 1) 해당 특징의 값 자체가 다른 특징보다 크다\n",
    " * 2) 특징 마다 값의 범위가 다르다\n",
    "\n",
    "#### 정말로 해당 특징이 그만큼의 중요도가 있는가?\n",
    "#### 헬렌은 세 가지 특징이 다 같은 정도의 중요도를 갖는다고 생각한다.\n",
    "  - 하지만 연간 항공 마일리지 수는 다른 특징에 비해 값 자체가 크다.\n",
    "  - 즉, 연간 항공 마일리지 수 특징의 값이 두 점 사이의 거리에 영향을 크게 미친다.\n",
    "  - 즉, 연간 항공 마일리지 수의 중요도가 높다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalization (정규화)\n",
    " * 값의 범위를 [0, 1] 또는 [-1, 1]로 변환하는 것\n",
    "\n",
    "#### [0, 1]로 정규화\n",
    "  newValue = (oldValue - min) / (max - min)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "##### Listing 2.3 Data-normailizing code for Python 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def autoNorm_p2(dataSet):\n",
    "    # 각 특징별 최솟값, 최댓값, 범위를 구함\n",
    "    minVals = dataSet.min(0)\n",
    "    maxVals = dataSet.max(0)\n",
    "    ranges = maxVals - minVals\n",
    "    \n",
    "    # 정규화된 배열로 사용할, dataSet과 같은 크기를 갖는 영행렬 준비\n",
    "    normDataSet = np.zeros(np.shape(dataSet))\n",
    "    \n",
    "    # dataSet의 각 행에서 최솟값을 빼기 위해 행 개수 준비\n",
    "    m = dataSet.shape[0]\n",
    "    \n",
    "    # np.tile 함수를 사용하여 최솟값 벡터를 dataSet과 행 개수가 같은 최솟값 배열로 만든 후\n",
    "    # dataSet 즉 oldValue에서 빼고 그 결과를 범위 배열로 나누어서 정규화된 값을 구함\n",
    "    normDataSet = dataSet - np.tile(minVals, (m, 1))\n",
    "    normDataSet = normDataSet / np.tile(ranges, (m, 1))\n",
    "    \n",
    "    # ranges와 minVals은 테스트 값에 대해 정규화할 필요가 있으므로 반환해야 함\n",
    "    return normDataSet, ranges, minVals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import kNN\n",
    "import importlib; importlib.reload(kNN)\n",
    "import numpy as np\n",
    "\n",
    "#datingDataMat, datingLabels = kNN.file2matrix('datingTestSet.txt')\n",
    "dataSet, dataLabels = kNN.file2matrix('datingTestSet.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "##### NumPy array methods\n",
    " - https://docs.scipy.org/doc/numpy/reference/arrays.ndarray.html#array-methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 각 특징별 최솟값, 최댓값, 범위를 구함\n",
    "minVals = dataSet.min(0)    # dataSet 배열의 열에 대한 최솟값, 0이 '열'을 의미\n",
    "maxVals = dataSet.max(0)\n",
    "ranges = maxVals - minVals; ranges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 정규화된 배열로 사용할, dataSet과 같은 크기를 갖는 영행렬 준비\n",
    "normDataSet = np.zeros(np.shape(dataSet)); normDataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# dataSet의 각 행에서 최솟값을 빼기 위해 행 개수 준비\n",
    "m = dataSet.shape[0]; m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# np.tile 함수를 사용하여 최솟값 벡터를 dataSet과 행 개수가 같은 최솟값 배열로 만든 후\n",
    "# dataSet 즉 oldValue에서 빼고 그 결과를 범위 배열로 나누어서 정규화된 값[0..1]을 구함\n",
    "normDataSet = dataSet - np.tile(minVals, (m, 1))\n",
    "normDataSet = normDataSet / np.tile(ranges, (m, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.tile(minVals, (m, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "normDataSet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Listing 2.3 Data-normailizing code for Python 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import kNN\n",
    "import importlib; importlib.reload(kNN)\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def autoNorm(dataSet):\n",
    "    # 각 특징별 최솟값, 최댓값, 범위를 구함\n",
    "    minVals = dataSet.min(0)\n",
    "    maxVals = dataSet.max(0)\n",
    "    ranges = maxVals - minVals\n",
    "    \n",
    "    # 정규화된 배열을 구함\n",
    "    normDataSet = (dataSet - minVals) / ranges\n",
    "    \n",
    "    # ranges와 minVals은 테스트 값에 대해 정규화할 필요가 있으므로 반환해야 함\n",
    "    return normDataSet, ranges, minVals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import kNN\n",
    "import importlib; importlib.reload(kNN)\n",
    "\n",
    "#datingDataMat, datingLabels = kNN.file2matrix('datingTestSet.txt')\n",
    "dataSet, dataLabels = kNN.file2matrix('datingTestSet.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 각 특징별 최솟값, 최댓값, 범위를 구함\n",
    "minVals = dataSet.min(0)\n",
    "maxVals = dataSet.max(0)\n",
    "ranges = maxVals - minVals; ranges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 정규화된 배열을 구함\n",
    "normDataSet = (dataSet - minVals) / ranges; normDataSet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 2.2.4 Test: testing the classifier as a whole program"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 기계 학습 알고리즘의 정확도\n",
    "  * 데이터의 90% 정도를 분류기(classifier) 학습에 사용\n",
    "  * 나머지 10%를 분류기의 정확도를 구하기 위한 테스트 데이터로 사용\n",
    "  * 이 10% 데이터는 임의로 선택\n",
    "  * 우리가 사용하는 데이터는 특정 순서로 저장된 것이 아니므로 처음 10% 또는 마지막 10%를 테스트 데이터로 선택하는 것이 임의로 10% 선택하는 것과 다를 바 없음\n",
    "### 에러율(error rate)\n",
    "  * error rate = 잘못 분류된 데이터 수 / 전체 데이터 수\n",
    "  * error rate = 0 ==> 완벽한 분류기\n",
    "  * error rate = 1.0 ==> 항상 잘못 분류하는 분류기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Listing 2.4 Classifier testing code for dating site for Python 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import kNN\n",
    "import importlib; importlib.reload(kNN)\n",
    "import numpy as np\n",
    "\n",
    "def datingClassTest_p2():\n",
    "    # 각종 변수 준비\n",
    "    hoRatio = 0.10                    # 테스트 데이터 비율 (10%)\n",
    "    datingDataMat, datingLabels = kNN.file2matrix('datingTestSet.txt')\n",
    "    normMat, ranges, minVals = kNN.autoNorm(datingDataMat)\n",
    "    m = normMat.shape[0]              # 데이터 총 개수, 로우 수\n",
    "    numTestVecs = int(m * hoRatio)    # 테스트 데이터 개수\n",
    "    errorCount = 0.0\n",
    "        \n",
    "    for i in range(numTestVecs):\n",
    "        classifierResult = kNN.classify0(normMat[i, :], normMat[numTestVecs:m, :], \\\n",
    "                                         datingLabels[numTestVecs:m], 3)        \n",
    "        # 교재에서는 %s 대신 %d, 교재대로 하려면 datingTestSet2.txt 파일을 사용\n",
    "        print(\"the classifier came back with: %s, the real answer is: %s\"\\\n",
    "                % (classifierResult, datingLabels[i]))\n",
    "        if (classifierResult != datingLabels[i]):\n",
    "            errorCount += 1.0\n",
    "            print(\"!!!NOT MATCHED!!!\")\n",
    "    print(\"the total error rate is: %f\" % (errorCount/float(numTestVecs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import kNN\n",
    "import importlib; importlib.reload(kNN)\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 각종 변수 준비\n",
    "hoRatio = 0.10                    # 테스트 데이터 비율 (10%)\n",
    "datingDataMat, datingLabels = kNN.file2matrix_p2('datingTestSet.txt')\n",
    "normMat, ranges, minVals = kNN.autoNorm_p2(datingDataMat)\n",
    "m = normMat.shape[0]              # 데이터 총 개수, 로우 수\n",
    "numTestVecs = int(m * hoRatio)    # 테스트 데이터 개수\n",
    "errorCount = 0.0\n",
    "print(normMat)\n",
    "print(ranges)\n",
    "print(minVals)\n",
    "print(m)\n",
    "print(numTestVecs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "i = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# i번째 테스트 데이터\n",
    "normMat[i, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 훈련 데이터\n",
    "normMat[numTestVecs:m, :].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# 레이블 데이터\n",
    "len(datingLabels[numTestVecs:m])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# kNN 수행: k 값은 3\n",
    "classifierResult = kNN.classify0(normMat[i, :], normMat[numTestVecs:m, :],\n",
    "                                datingLabels[numTestVecs:m], 3)\n",
    "classifierResult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(\"the classifier came back with: %s, the real answer is: %s\"\\\n",
    "                % (classifierResult, datingLabels[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if (classifierResult != datingLabels[i]):\n",
    "    errorCount += 1.0\n",
    "errorCount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# i 값을 변경시켜가며 결과를 확인해 본다.\n",
    "i = 99\n",
    "\n",
    "# kNN 수행: k 값은 3\n",
    "classifierResult = kNN.classify0(normMat[i, :], normMat[numTestVecs:m, :],\n",
    "                                datingLabels[numTestVecs:m], 3)\n",
    "print(\"the classifier came back with: %s, the real answer is: %s\"\\\n",
    "                % (classifierResult, datingLabels[i]))\n",
    "if (classifierResult != datingLabels[i]):\n",
    "    errorCount += 1.0\n",
    "errorCount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "datingClassTest_p2()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Listing 2.4 Classifier testing code for dating site for Python 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import kNN\n",
    "import importlib\n",
    "importlib.reload(kNN)\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "\"\"\"\n",
    "file: 테스트 데이터 파일 이름\n",
    "ratio: 테스트 데이터 비율\n",
    "k: kNN의 k 값\n",
    "\n",
    "입력 데이터 중 [0, 총데이터*테스트비율) 범위의 데이터가 테스트 데이터로 사용된다.\n",
    "\"\"\"\n",
    "def datingClassTest_v1(file, ratio = 0.1, k = 3):\n",
    "    # 각종 변수 준비\n",
    "    datingDataMat, datingLabels = kNN.file2matrix(file)\n",
    "    normMat, ranges, minVals = kNN.autoNorm(datingDataMat)\n",
    "    numTotal = normMat.shape[0]            # 데이터 총 개수, 로우 수\n",
    "    numTestVecs = int(numTotal * ratio)    # 테스트 데이터 개수\n",
    "    errorCount = 0\n",
    "        \n",
    "    for i in range(numTestVecs):\n",
    "        classifierResult = kNN.classify0(normMat[i, :], normMat[numTestVecs:m, :], \\\n",
    "                                         datingLabels[numTestVecs:m], k)        \n",
    "        # 교재에서는 %s 대신 %d, 교재대로 하려면 datingTestSet2.txt 파일을 사용\n",
    "        print(\"the classifier came back with: %s, the real answer is: %s\"\\\n",
    "                % (classifierResult, datingLabels[i]))\n",
    "        if (classifierResult != datingLabels[i]):\n",
    "            errorCount += 1\n",
    "            print(\"!!!NOT MATCHED!!!\")\n",
    "    print(\"the total error rate is: %f\" % (errorCount/float(numTestVecs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classifierResult = [kNN.classify0(normMat[i, :], normMat[numTestVecs:m, :], \n",
    "                            datingLabels[numTestVecs:m], 3) for i in range(numTestVecs)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "numTestVecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "normMat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "a = np.array(classifierResult) != np.array(datingLabels[:numTestVecs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.array(datingLabels[:numTestVecs])[a].size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "normMat.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "aa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = [1, 2, 3,4, 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.array(a) > 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "type(ranges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ranges.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "datingClassTest_v1('datingTestSet.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "datingClassTest_v1('datingTestSet.txt', k = 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "datingClassTest_v1('datingTestSet.txt', k = 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "datingClassTest_v1('datingTestSet.txt', k = 11)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2.5 Use: putting together a useful system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import kNN\n",
    "import importlib\n",
    "importlib.reload(kNN)\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Listing 2.5 Dating site predictor function Python 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def classifyPerson():\n",
    "    resultList = ['not at all','in small doses', 'in large doses']\n",
    "    percentTats = float(raw_input(\\\n",
    "                 \"percentage of time spent playing video games?\"))\n",
    "    ffMiles = float(raw_input(\"frequent flier miles earned per year?\"))\n",
    "    iceCream = float(raw_input(\"liters of ice cream consumed per year?\"))\n",
    "    datingDataMat,datingLabels = file2matrix('datingTestSet.txt')\n",
    "    normMat, ranges, minVals = autoNorm(datingDataMat)\n",
    "    inArr = array([ffMiles, percentTats, iceCream])\n",
    "    classifierResult = classify0((inArr-minVals)/ranges,\n",
    "                                 normMat, datingLabels, 3)\n",
    "    print \"You will probably like this person: \",\\\n",
    "                   resultList[classifierResult - 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Listing 2.5 Dating site predictor function Python 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def classifyPerson():\n",
    "    resultList = ['not at all','in small doses', 'in large doses']\n",
    "    percentTats = float(input(\\\n",
    "                 \"percentage of time spent playing video games?\"))\n",
    "    ffMiles = float(input(\"frequent flier miles earned per year?\"))\n",
    "    iceCream = float(input(\"liters of ice cream consumed per year?\"))\n",
    "    datingDataMat,datingLabels = file2matrix('datingTestSet2.txt')\n",
    "    normMat, ranges, minVals = autoNorm(datingDataMat)\n",
    "    inArr = np.array([ffMiles, percentTats, iceCream])\n",
    "    classifierResult = classify0((inArr-\\\n",
    "                   minVals)/ranges,normMat,datingLabels,3)\n",
    "    print(\"You will probably like this person:\",\n",
    "              #classifierResult)    # for datingTestSet.txt\n",
    "                   resultList[int(classifierResult) - 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classifyPerson()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Example: a handwriting recognition system"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Collect:\n",
    "  - 텍스트 파일로 제공됨, 2000여개의 샘플\n",
    "2. Prepare:\n",
    "  - 이미지 포맷을 리스트 포맷으로 변환하는 함수 작성\n",
    "  - 이렇게 변환된 리스트는 앞서 작성한 kNN 분류 함수 classify0()에 사용됨\n",
    "3. Analyze:\n",
    "  - 리스트 포맷으로 잘 변환되었는지 파이썬 셀에서 확인\n",
    "4. Train:\n",
    "  - kNN은 훈련 과정이 없음\n",
    "5. Test:\n",
    "  - 데이터 일부를 테스트 예제(샘플)로 사용하는 함수 작성\n",
    "  - 이 함수를 통해 테스트 데이터와 kNN 데이터로 구분\n",
    "  - 테스트 데이터의 분류 예측 결과와 실제 클래스가 일치하지 않으면 에러로 처리\n",
    "6. Use:\n",
    "  - 여기서는 수행하지 않음\n",
    "  - 필요하다면 이를 응용한 애플리케이션 작성 가능\n",
    "    - 우편 봉투 이미지에서 우편 번호를 추출하여 우편물 정리하는데 이용 등\n",
    "    - 다른 활용예도 생각해 봅시다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3.1 Prepare: converting images into test vectors\n",
    "\n",
    "  * 숫자 이미지 크기: 32x32\n",
    "  * 훈련용 데이터: 2,000 개\n",
    "    - 번호별 약 200개 표본\n",
    "    - 번호별 디렉터리에 존재\n",
    "  * 테스트용 데이터: 약 900 개\n",
    "  \n",
    "  \n",
    "  * 2차원 이미지 데이터를 1차원 벡터로 변환\n",
    "    - 32x32 ==> 1x1024\n",
    "    - 이전에 개발한 classify0() 분류기 함수를 사용하기 위해\n",
    "    - img2vector()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Listing Converting number image to vector Python 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def img2vector(filename):\n",
    "    returnVect = pd.zeros((1,1024))\n",
    "    fr = open(filename)\n",
    "    for i in range(32):\n",
    "        lineStr = fr.readline()\n",
    "        for j in range(32):\n",
    "            returnVect[0,32*i+j] = int(lineStr[j])\n",
    "    return returnVect"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3.2 Analyze: looking at the prepared data in the Python shell to make sure it’s correct\n",
    "  - testDigits/0_13.txt를 편집기로 열어서 아래 testVector의 내용과 일치하는지 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "testVector = kNN.img2vector('testDigits/0_13.txt')\n",
    "testVector[0, 0:31]\n",
    "testVector[0, 32:63]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3.3 Test: kNN on handwritten digits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Listing 2.6 Handwritten digits testing code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def handwritingClassTest():\n",
    "    hwLabels = []\n",
    "    trainingFileList = os.listdir('trainingDigits')   \n",
    "    m = len(trainingFileList)\n",
    "    trainingMat = np.zeros((m,1024))\n",
    "    for i in range(m):\n",
    "        fileNameStr = trainingFileList[i]        \n",
    "        fileStr = fileNameStr.split('.')[0]             \n",
    "        classNumStr = int(fileStr.split('_')[0]) \n",
    "        hwLabels.append(classNumStr)\n",
    "        trainingMat[i,:] = kNN.img2vector('trainingDigits/%s' % fileNameStr)\n",
    "    testFileList = os.listdir('testDigits')\n",
    "    errorCount = 0.0\n",
    "    mTest = len(testFileList)\n",
    "    for i in range(mTest):\n",
    "        fileNameStr = testFileList[i]\n",
    "        fileStr = fileNameStr.split('.')[0]\n",
    "        classNumStr = int(fileStr.split('_')[0])\n",
    "        vectorUnderTest = kNN.img2vector('testDigits/%s' % fileNameStr)\n",
    "        classifierResult = kNN.classify0(vectorUnderTest, \\\n",
    "                                trainingMat, hwLabels, 3)\n",
    "        print \"the classifier came back with: %d, the real answer is: %d\"\\\n",
    "                                % (classifierResult, classNumStr)\n",
    "        if (classifierResult != classNumStr): errorCount += 1.0\n",
    "    print(\"\\nthe total number of errors is: %d\" % errorCount)\n",
    "    print(\"\\nthe total error rate is: %f\" % (errorCount/float(mTest)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "kNN.handwritingClassTest()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4 Summary\n",
    "  * 특징\n",
    "    - instance-based learning의 한 예\n",
    "  * 장점\n",
    "    - 간단\n",
    "    - 분류에 효과적\n",
    "  * 단점\n",
    "    - 전체 데이터를 다루어야 하므로 큰 데이터 집합을 처리하려면 큰 저장소 필요\n",
    "    - 모든 데이터에 대해 거리 계산 --> 연산 부담\n",
    "    - 데이터 구조에 대한 어떠한 정보도 얻을 수 없음\n",
    "      - 같은 부류의 데이터에 대한 평균, 모범예 등을 알 수 없음    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
